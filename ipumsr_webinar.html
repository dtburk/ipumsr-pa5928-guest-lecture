<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Using IPUMS data in R with ipumsr</title>
    <meta charset="utf-8" />
    <meta name="author" content="Derek Burk, Dan Ehrlich, &amp; Kara Fisher" />
    <meta name="date" content="2021-10-12" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
    <script src="libs/jquery-3.5.1/jquery.min.js"></script>
    <link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding-0.17/datatables.js"></script>
    <link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
    <script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Using IPUMS data in R with ipumsr
### Derek Burk, Dan Ehrlich, &amp; Kara Fisher
### 10/12/2021

---







&lt;style&gt;
.grid-logo {
  background-image: url(logos/grid.png);
  background-size: cover;
  width: 400px;
  height: 400px;
  position: absolute;
  right: 75px;

}
&lt;/style&gt;


&lt;style&gt;
.derek-pet {
  background-color: #000000;
  background-image: url(logos/derek2.jpg);
  background-size: cover;
  width: 98px;
  height: 120px;
}
&lt;/style&gt;


&lt;style&gt;
.dan-pet1 {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;
  position: absolute;
  left: 200px;
  
}
&lt;/style&gt;


&lt;style&gt;
.dan-pet2 {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;  
  position: absolute;
  left: 400px;
}
&lt;/style&gt;

&lt;style&gt;
.kara-pet {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;
  position: absolute;
  left: 600px;
  bottom: 400px;
}
&lt;/style&gt;


&lt;style&gt;
.isrdi-logo {
  background-image: url(logos/isrdi2.jpg);
  background-size: cover;
  height: 186px;
  width: 604px;
  position: absolute;
  bottom: 15px;
  left: 15;
}
&lt;/style&gt;



&lt;style&gt;
.names {
  font-size: 1.5em;
}
&lt;/style&gt;

&lt;style&gt;
  .greyed-out {
    color: #D3D3D3;
    text-indent: 20px;
  }
&lt;/style&gt;

&lt;style&gt;
  .strong {
    color: #000000;
    text-indent: 20px;
  }
&lt;/style&gt;



&lt;style&gt;
.dan-pet1 {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;
  position: absolute;
  left: 200px;
  
}
&lt;/style&gt;


&lt;style&gt;
.dan-pet2 {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;  
  position: absolute;
  left: 400px;
}
&lt;/style&gt;

&lt;style&gt;
.kara-pet {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;
  position: absolute;
  left: 600px;
  bottom: 400px;
}
&lt;/style&gt;



---


# Who we are


.isrdi-logo[

]

--

.left[
Derek Burk, PhD 

Sociology
]

--

.center[
Dan Ehrlich,MA

Anthropology


]

--

.right[


Kara Fisher,
MPH

Public Health

]


???
Name, pronouns, time with IPUMS


---

# Who we are

.isrdi-logo[]


.derek-pet[

]

.dan-pet1[]

.dan-pet2[]

.kara-pet[]

&lt;style&gt;
.derek-pet {
  background-color: #000000;
  background-image: url(logos/derek2.jpg);
  background-size: cover;
  width: 98px;
  height: 120px;
  position: absolute;
  left: 150px;
  top: 150px;
}
&lt;/style&gt;


&lt;style&gt;
.dan-pet1 {
  background-color: #d3d3d3;
  background-size: cover;
  width: 120px;
  height: 120px;
  position: absolute;
  left: 300px;
  top: 250px;
  
}
&lt;/style&gt;


&lt;style&gt;
.dan-pet2 {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;  
  position: absolute;
  left: 450px;
  top: 250px;
}
&lt;/style&gt;

&lt;style&gt;
.kara-pet {
  background-color: #000000;
  background-size: cover;
  width: 120px;
  height: 120px;
  position: absolute;
  left: 650px;
  bottom: 200px;
}
&lt;/style&gt;


???

Rather than our faces, we thought everyone would appreciate pets.

**A FEW NOTES**

This presentation will be recorded and will be available along with slides so don't worry about trying to take notes.

You can always reach out to through our **github**, or via **user support**.

---

# Overview

1. What is IPUMS?

--

2. What is ipumsr, and why use it?

--

3. Reading data into R

--

4. Exploring and manipulating metadata

--

5. Brief analysis example

--

6. Working with IPUMS geographic data

--

7. Preview of IPUMS API functionality

--

8. Q &amp; A

---

# Overview



.greyed-out[


.strong[`1.` What is IPUMS?]

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]


---



class: center

# What is IPUMS?

--

## IPUMS is **data**

--

## from censuses and surveys around the world,

--

## integrated across space and time,

--

## thoroughly documented,

--

## and available for free at ipums.org

???



ipums has grown substantially over the past 20?? years, 

started with **US census data** has grown to include 9 collections

*mostly just segueing to projects*

---

class: center, middle

# Poll: Which IPUMS data collections are you most interrested in exploring?


---
# 
![IPUMS US Project logo](logos/usa.jpg)

--

- U.S. Census and American Community Survey **microdata** from 1850 to the present.

- 180,755,919 unique person records from decennial census and Anual community Survey.

- 191,983,898 historical personrecords from full count decennial census from 1850-1940 (1890 census lost due to fire).

- https://usa.ipums.org/usa/

???




---

# 
![IPUMS CPS project logo](logos/cps.jpg)

--

- Current Population Survey **microdata** from 1962 to the present.

- Monthly labor force surveys and supplements.



---

# 
![IPUMS NHGIS project logo](logos/int.jpg)

--


- Census **microdata** covering a102 countries from 1960 to the present 


- International historic **microdata** from the 19th and early 20th centuries for *9* countries.

--

- Labor Force surveys provide high resolution **microdata** about work conditions

  - Adminstered quarterly (usually) with records going back at least 10 years (usually)
  - Currently available for Italy (2011-2020) &amp; Spain (2005-2020)
  - Mexico (2005-2020) coming soon!




---
# 
![IPUMS Global Health project logo](logos/dhs.jpg)


--


- Demographic and Health Surveys (DHS) provide integrated **microdata** for analysis across time and space.
  - From the 1980s to the present.
  - Covering Africa and South Asia
  
- Performance Monitoring for Action (PMA) surveys
  - Focus on fertility, contraception, hygiene, and health
  - Administered frequently to monitor trends in select high-fertility countries.
  - https://ipums.github.io/pma-data-hub/index.html#category:PMA_Publications

???

Check out Matt Gunther's blog using IPUMS Global Health Data

---
# 
![IPUMS Health Surveys project logo](logos/health.jpg)


--


- Health **survey** data from the National Health Interview Survey (NHIS) from the 1960s to the present and the Medical Expenditure Panel Survey (MEPS) from 1996.

- Supplements on cost of healthcare.

???


---

# 
![IPUMS Higher Ed project logo](logos/highered.jpg)

--


- Scientists and Engineers Statistical Data System (SESTAT), the leading surveys for studying the science and engineering (STEM) workforce in the United States

- Data from the National Surveys of College Graduates (NSCG), Recent College Graduates (NSRCG) and Doctorate Recipients (SDR) are integrated from 1993 to the present.



---

#
![IPUMS Time Use project logo](logos/time_use.jpg)

--

- Historical and contemporary time use data from 1965 to the present.

- Extensive time diary data from respondents in the US and *7* other countries.

---

# 
![IPUMS NHGIS project logo](logos/nhgis.jpg)


--

- Summary tables and time series of population, housing, agriculture, and economic data 

- GIS Shapefiles for all levels of US geography, including tracts, from 1790 to the present

---


![IPUMS IHGIS project logo](logos/ihgis.jpg)

--

- **Summary** data tables from population and housing censuses as well as agricultural censuses from around the world

- Integrated GIS **shapefiles.**

---

# So What is Ipums?


.grid-logo[

]

.pull-left[
- IPUMS is **a lot** of data

- United in consistently documented metadata
]

---

# So What is Ipums?


.grid-logo[

]


.pull-left[
- IPUMS is **a lot** of data

- United in consistently documented metadata

- *What's the best way to interact with IPUMS data?*
]




???

So ipums really is **data** and a whole lot of it. These 9 different projects interact with different types of data and at different scales but they are united in 

---


class: center, middle

# Poll: Which IPUMS data collections have you used?

---


# Overview

.greyed-out[


`1.` What is IPUMS?

.strong[`2.` What is ipumsr, and why use it?]

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]


---



# What is ipumsr?

- R package developed by Greg Freedman Ellis

--

- Released in 2017

--

- Over 90,000 CRAN downloads

--

- Includes functions for
  - Reading IPUMS data
  - Exploring and manipulating IPUMS metadata
  - **SOON**: Interacting with the IPUMS API
    
    
???
(Metadata such as value labels, variable labels, and detailed variable 
descriptions.)

Initial API support will be for IPUMS USA, with more projects to follow soon.



---

# Why use ipumsr?

- One package for IPUMS microdata, aggregate data, and geography

???
Regarding "One package": Without ipumsr, you'd need to use a variety of
different approaches from different packages to read in and explore IPUMS
microdata (from projects such as IPUMS USA, CPS, and International), IPUMS
aggregate data (from NHGIS or IHGIS), and IPUMS shapefiles. ipumsr provides one
package with a consistent interface for working with all these different types
of IPUMS data.

---

class: center middle inverse
background-image: url(https://comicvine.gamespot.com/a/uploads/original/5/52246/1963701-the_one_ring_02.jpg)
background-size: cover

&lt;span role="img" aria-label="Slide background shows: The 'One Ring' from The Lord of the Rings set on a fiery background."&gt;&lt;/span&gt;

# One package to rule them all



&lt;img src="screenshots/transparent_blank.png" title="Slide background shows: The 'One Ring' from The Lord of the Rings set on a fiery background." alt="Slide background shows: The 'One Ring' from The Lord of the Rings set on a fiery background."  /&gt;

---

# Why use ipumsr?

- One package for IPUMS microdata, aggregate data, and geography

- Specialized functions for viewing and manipulating IPUMS metadata

--

- Bundled how-to guides (vignettes)

--

- Potential to add more features (e.g. API support); let us know what you want!
  - File an issue at https://github.com/mnpopcenter/ipumsr/issues
  - Email ipums+cran@umn.edu

???
Regarding "More features": The aforementioned IPUMS API support will be the next
big feature. Another potential new feature is adding tools for properly handling
survey weights. Let us know what would be helpful to you via GitHub or email.

---

# Why use ipumsr?

And finally... 

--

- It's fast!
  - Time to read 3 million rows with 13 variables:

<div id="bnmkyyktjb" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#bnmkyyktjb .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#bnmkyyktjb .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#bnmkyyktjb .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#bnmkyyktjb .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#bnmkyyktjb .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#bnmkyyktjb .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#bnmkyyktjb .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#bnmkyyktjb .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#bnmkyyktjb .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#bnmkyyktjb .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#bnmkyyktjb .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#bnmkyyktjb .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#bnmkyyktjb .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#bnmkyyktjb .gt_from_md > :first-child {
  margin-top: 0;
}

#bnmkyyktjb .gt_from_md > :last-child {
  margin-bottom: 0;
}

#bnmkyyktjb .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#bnmkyyktjb .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#bnmkyyktjb .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#bnmkyyktjb .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#bnmkyyktjb .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#bnmkyyktjb .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#bnmkyyktjb .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#bnmkyyktjb .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#bnmkyyktjb .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#bnmkyyktjb .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#bnmkyyktjb .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#bnmkyyktjb .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#bnmkyyktjb .gt_left {
  text-align: left;
}

#bnmkyyktjb .gt_center {
  text-align: center;
}

#bnmkyyktjb .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#bnmkyyktjb .gt_font_normal {
  font-weight: normal;
}

#bnmkyyktjb .gt_font_bold {
  font-weight: bold;
}

#bnmkyyktjb .gt_font_italic {
  font-style: italic;
}

#bnmkyyktjb .gt_super {
  font-size: 65%;
}

#bnmkyyktjb .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Function</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Time (seconds)</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">With metadata?</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">data.table::fread()</td>
<td class="gt_row gt_center">2.5</td>
<td class="gt_row gt_center">No</td></tr>
    <tr><td class="gt_row gt_left">vroom::vroom()</td>
<td class="gt_row gt_center">2.5</td>
<td class="gt_row gt_center">No</td></tr>
    <tr><td class="gt_row gt_left">ipumsr::read_ipums_micro()</td>
<td class="gt_row gt_center">3.3</td>
<td class="gt_row gt_center">Yes</td></tr>
    <tr><td class="gt_row gt_left">haven::read_dta()</td>
<td class="gt_row gt_center">7.8</td>
<td class="gt_row gt_center">Yes</td></tr>
    <tr><td class="gt_row gt_left">haven::read_sav()</td>
<td class="gt_row gt_center">9.4</td>
<td class="gt_row gt_center">Yes</td></tr>
    <tr><td class="gt_row gt_left">readr::read_csv()</td>
<td class="gt_row gt_center">9.8</td>
<td class="gt_row gt_center">No</td></tr>
  </tbody>
  
  
</table>
</div>

???
There are other ways to read IPUMS data into R, but ipumsr is the fastest way 
to read the data in with attached metadata, such as variable and value labels.

---

class: center, middle

# Poll: How much have you used ipumsr?

---

# Installing ipumsr

```r
install.packages("ipumsr")
```

--

### Or if you want the development version

- www.github.com/mnpopcenter/ipumsr


```r
if (!require(remotes)) install.packages("remotes")
remotes::install_github("mnpopcenter/ipumsr")
```

???
Now that we've convinced you of how great ipumsr is, you're probably asking 
"How do I get my hands on it?"

---
class: center, middle

# To follow allong with this webinar
---

# Downloading your data extract

&lt;img src="screenshots/microdata_annotated_screenshot.png" title="Screenshot of IPUMS data download page with overlaid instructions: 1. Click the 'Download .DAT' link to download the data. 2. Right click the 'DDI' link. 3. In the right-click menu, choose 'Save link as' in Firefox or Chrome, or 'Download Linked File' in Safari." alt="Screenshot of IPUMS data download page with overlaid instructions: 1. Click the 'Download .DAT' link to download the data. 2. Right click the 'DDI' link. 3. In the right-click menu, choose 'Save link as' in Firefox or Chrome, or 'Download Linked File' in Safari."  /&gt;

--

???

Kind of confusing how to save the DDI/.xml file. THIS IS HOW


Make sure to save the data and DDI files in the same location.


R download link contains instructions that we're about to cover here

---

# Downloading your data extract

&lt;img src="screenshots/download_screenshot_2.png" title="Screenshot of IPUMS data download page with the 'R' link highlighted" alt="Screenshot of IPUMS data download page with the 'R' link highlighted"  /&gt;

- The "R" link on the downloads page contains this helper code:


```r
# NOTE: To load data, you must download both the extract's data and the DDI
# and also set the working directory to the folder with these files (or change the path below).

if (!require("ipumsr")) stop("Reading IPUMS data into R requires the ipumsr package. It can be installed using the following command: install.packages('ipumsr')")

ddi &lt;- read_ipums_ddi("ipumsi_00059.xml")
data &lt;- read_ipums_micro(ddi)
```

???
This helper code checks that you have ipumsr installed, and if you do, it reads
in the DDI codebook and data into separate objects. As an aside, in case anyone
was curious, DDI stands for "Data Documentation Initiative" -- the DDI project
sets standards for documenting datasets, and the codebooks for most IPUMS
projects follow this standard.

We'll see this same code pattern in just a moment when we look at how to read 
in your data.

---


# Install R packages (as needed)


```r


# install.packages(ipumsr)

## Tidyverse
install.packages(dplyr)
install.packages(ggplot2)
install.packages(stringr)
install.packages(purrr)

## gis
install.packages(sf)

```

---



# Loading packages

```r
library(ipumsr)
library(dplyr)
library(ggplot2)
library(stringr)
library(sf)
library(purrr)

```



???
These packages are used in some of the examples we will walk through.

---


# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

.strong[`3.` Reading data into R]

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]


???

Dan passes to Kara

---

# Read in the data
- Using functions `read_ipums_ddi()` and `read_ipums_micro()`

```r
ddi &lt;- read_ipums_ddi("usa_00013.xml")

data &lt;- read_ipums_micro(ddi)
#&gt; Use of data from IPUMS-USA is subject to conditions including that users should
#&gt; cite the data appropriately. Use command `ipums_conditions()` for more details.
```

???
Here we see the same code pattern from the "R" helper file above, of reading the
metadata from the codebook into an object named "ddi", and using that object to 
read in the data.

--- 

# Read in the data

- Can also just use `read_ipums_micro()`


```r
data &lt;- read_ipums_micro("usa_00013.xml")
#&gt; Use of data from IPUMS-USA is subject to conditions including that users should
#&gt; cite the data appropriately. Use command `ipums_conditions()` for more details.
```

???
You can also just read the data by passing the file path to the DDI codebook to 
the `read_ipums_micro()` function, but it's often helpful to save the codebook 
to it's own object to preserve the original metadata once you start messing 
around with the data.

---

# What's in that `ddi` object?


```r
names(ddi)
#&gt;  [1] "file_name"        "file_path"       
#&gt;  [3] "file_type"        "ipums_project"   
#&gt;  [5] "extract_date"     "extract_notes"   
#&gt;  [7] "rectypes"         "rectype_idvar"   
#&gt;  [9] "rectypes_keyvars" "var_info"        
#&gt; [11] "conditions"       "citation"        
#&gt; [13] "file_encoding"
```

???
So what's in that ddi object? A bunch of information about your extract, but 
perhaps the most important element for understanding and analyzing the data is 
the "var_info" data.frame.

---

# What's in that `ddi` object?


```r
ddi$var_info
#&gt; # A tibble: 12 x 10
#&gt;    var_name var_label     var_desc     val_labels 
#&gt;    &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;        &lt;list&gt;     
#&gt;  1 YEAR     Census year   "YEAR repor~ &lt;tibble[,2~
#&gt;  2 DATANUM  Data set num~ "DATANUM id~ &lt;tibble[,2~
#&gt;  3 SERIAL   Household se~ "SERIAL is ~ &lt;tibble[,2~
#&gt;  4 HHWT     Household we~ "HHWT indic~ &lt;tibble[,2~
#&gt;  5 STATEFIP State (FIPS ~ "STATEFIP r~ &lt;tibble[,2~
#&gt;  6 CONSPUMA Consistent P~ "CONSPUMA i~ &lt;tibble[,2~
#&gt;  7 GQ       Group quarte~ "GQ classif~ &lt;tibble[,2~
#&gt;  8 PHONE    Telephone av~ "PHONE indi~ &lt;tibble[,2~
#&gt;  9 PERNUM   Person numbe~ "PERNUM num~ &lt;tibble[,2~
#&gt; 10 PERWT    Person weight "PERWT indi~ &lt;tibble[,2~
#&gt; 11 EDUC     Educational ~ "EDUC indic~ &lt;tibble[,2~
#&gt; 12 EDUCD    Educational ~ "EDUC indic~ &lt;tibble[,2~
#&gt; # ... with 6 more variables: code_instr &lt;chr&gt;,
#&gt; #   start &lt;dbl&gt;, end &lt;dbl&gt;, imp_decim &lt;dbl&gt;,
#&gt; #   var_type &lt;chr&gt;, rectypes &lt;lgl&gt;
```


???
As we can see here, var_info is just data.frame where each row has information 
about one variable, including the variable name, label, description, and value 
labels, as well as where the variable is located in the fixed-width file.

You don't need to know this to use ipumsr, but it might help you understand 
what is going on when you read in the DDI codebook and then the data.


---

# What's in my extract again?

--

Maybe I wrote an informative extract description?




```r
ddi$extract_notes %&gt;% strwrap(30)
#&gt; [1] "User-provided description:"   
#&gt; [2] "Revision of(Revision"         
#&gt; [3] "of(Revision of(Revision of(my"
#&gt; [4] "extract))))"
```

--

No such luck 😞

???
So we've read in our data -- how do we go about exploring it?

We could refer back to the description we wrote when creating the extract, 
maybe that will be informative. Let's see (read extract description). Ooh, 
that's not very helpful. I'm guessing this joke hits close to home for some of 
you long-time IPUMS users.

---

# What's in my extract again?

We can print the names of our variables:

--


```r
names(data)
#&gt;  [1] "YEAR"     "DATANUM"  "SERIAL"   "HHWT"    
#&gt;  [5] "STATEFIP" "CONSPUMA" "GQ"       "PHONE"   
#&gt;  [9] "PERNUM"   "PERWT"    "EDUC"     "EDUCD"
```


But often variable names aren't self-explanatory.

--

Let's leverage that attached metadata!

???
[Read text on slides]

---


# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

.strong[`4.` Exploring and manipulating metadata]

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]

---

# Available metadata
- Some (but not all) of the documentation comes with the ddi

```r
ipums_var_label(ddi, PHONE)
#&gt; [1] "Telephone availability"

ipums_var_desc(ddi, PHONE) %&gt;% strwrap(60)
#&gt; [1] "PHONE indicates whether residents of the housing unit had"
#&gt; [2] "telephone access."
```

???
So you can see here that ipumsr provides function to extract information from 
the DDI object without the need to slice and dice that "var_info" data.frame I 
showed before. Here we grab the label and description for the variable PHONE.

---

# Available metadata

```r
ipums_val_labels(ddi, PHONE)
#&gt; # A tibble: 4 x 2
#&gt;     val lbl                           
#&gt;   &lt;dbl&gt; &lt;chr&gt;                         
#&gt; 1     0 N/A                           
#&gt; 2     1 No, no phone available        
#&gt; 3     2 Yes, phone available          
#&gt; 4     8 Suppressed (2012 and 2015 ACS)
```

???
Similarly, we can print the value labels by pointing to the DDI. We see here 
that the variable PHONE takes four values: no, yes, not applicable, and 
suppressed.

---


# An interactive view of metadata


```r
ipums_view(ddi)
```

&lt;img src="screenshots/ipums_view_screenshot.png" title="Screenshot of static html page generated by function 'ipums_view', showing variable label and variable description for the variable 'PHONE'." alt="Screenshot of static html page generated by function 'ipums_view', showing variable label and variable description for the variable 'PHONE'."  /&gt;

???
For a more browsable view of the metadata, the ipums_view() function makes a
nicely-formatted static html page that allows you to browse the metadata
associated with your data extract.


---

# Wrangling value labels

- IPUMS value labels don't translate perfectly to R factors.

    - (Factors always have a label, and always have values starting at 1)
  
- So `ipumsr` imports them as `haven::labelled()` objects, which aren't
  always the easiest to deal with.

- Luckily ipumsr provides helpers that allow you to use information
  from both the value and label



???
IPUMS value labels don't translate perfectly to R factors. The most important 
difference is that in a factor, values always count up from 1. In IPUMS 
variables, the values themselves often encode meaningful information about a 
nested structure, which we'll see with the education variable below.
  
To preserve both the value and label, `ipumsr` imports labelled variables as
`haven::labelled()` objects, but these aren't always the easiest to deal with, 
because they aren't widely supported by functions from base R and other 
packages.

Luckily ipumsr provides helpers that allow you to use information from both the
value and label.

---

# Group quarters variable


```r
ipums_val_labels(data$GQ)
#&gt; # A tibble: 7 x 2
#&gt;     val lbl                                       
#&gt;   &lt;int&gt; &lt;chr&gt;                                     
#&gt; 1     0 Vacant unit                               
#&gt; 2     1 Households under 1970 definition          
#&gt; 3     2 Additional households under 1990 definiti~
#&gt; 4     3 Group quarters--Institutions              
#&gt; 5     4 Other group quarters                      
#&gt; 6     5 Additional households under 2000 definiti~
#&gt; 7     6 Fragment
```

???
Here we see another way to print value labels, by pointing directly at the 
variable in the data.frame. This only works, however, if the variable is still 
a `haven::labelled()` vector.

How you want to transform any given variable will always depend on what you 
want to do with it, but in the case of GQ, it doesn't look like the values are 
giving us much information, so perhaps we just want to convert directly to a 
factor.

---

# `as_factor()`

- Suppose we want to keep these labels exactly as they are.


```r
data$GQ2 &lt;- as_factor(data$GQ)
```

. . .

<div id="htmlwidget-0c848fcfa04c843e67a2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-0c848fcfa04c843e67a2">{"x":{"filter":"none","data":[["[0] Vacant unit","[1] Households under 1970 definition","[2] Additional households under 1990 definition","[3] Group quarters--Institutions","[4] Other group quarters","[5] Additional households under 2000 definition","[6] Fragment"],["Vacant unit","Households under 1970 definition","Additional households under 1990 definition","Group quarters--Institutions","Other group quarters","Additional households under 2000 definition","Fragment"],[0,1433423,1712,19592,21541,175,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

???
`as_factor()` (from haven) converts a labelled vector directly to a factor by 
using the value labels as the factor levels.

[Read the table a bit]

---

# `lbl_clean()`
- `lbl_clean()` gets rid of unused value labels.


```r
ipums_val_labels(data$STATEFIP)
#&gt; # A tibble: 62 x 2
#&gt;      val lbl                 
#&gt;    &lt;int&gt; &lt;chr&gt;               
#&gt;  1     1 Alabama             
#&gt;  2     2 Alaska              
#&gt;  3     4 Arizona             
#&gt;  4     5 Arkansas            
#&gt;  5     6 California          
#&gt;  6     8 Colorado            
#&gt;  7     9 Connecticut         
#&gt;  8    10 Delaware            
#&gt;  9    11 District of Columbia
#&gt; 10    12 Florida             
#&gt; # ... with 52 more rows
```

???
Now let's get the ipumsr helper functions for labelled vectors.

Sometimes we might want to get rid of values with zero frequency before 
converting to factor. Here, the labels for STATEFIP include all 50 states...

---

# `lbl_clean()`
- Since our extract only has Minnesota, we don't want all of
 these values.


```r
data$STATEFIP2 &lt;- data$STATEFIP %&gt;% 
  lbl_clean() %&gt;% 
  as_factor()
```

. . .

<div id="htmlwidget-7366e8de28c4ff51cc19" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-7366e8de28c4ff51cc19">{"x":{"filter":"none","data":[["[27] Minnesota"],["Minnesota"],[1476443]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

???
...but our extract only includes Minnesota, so we might not need to preserve all 
those labels.

---

# `lbl_na_if()`
- `lbl_na_if()` allows you to set certain values or labels 
  to missing.


```r
ipums_val_labels(data$PHONE)
#&gt; # A tibble: 4 x 2
#&gt;     val lbl                           
#&gt;   &lt;int&gt; &lt;chr&gt;                         
#&gt; 1     0 N/A                           
#&gt; 2     1 No, no phone available        
#&gt; 3     2 Yes, phone available          
#&gt; 4     8 Suppressed (2012 and 2015 ACS)
```

???
In this case, it makes sense to set values 0 and 8 to missing, given the value 
labels we're seeing here.

---

# `lbl_na_if()`



```r
data$PHONE2 &lt;- lbl_na_if(data$PHONE, ~.val %in% c(0, 8)) %&gt;%
  as_factor()
```

. . . 

<div id="htmlwidget-a05d23db46e999017447" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-a05d23db46e999017447">{"x":{"filter":"none","data":[["[0] N/A","[1] No, no phone available","[2] Yes, phone available","[8] Suppressed (2012 and 2015 ACS)"],[null,"No, no phone available","Yes, phone available",null],[41133,30852,1404458,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

???
`lbl_na_if()` supports a special syntax used by a few of ipumsr's label 
functions that allows you to refer to either the value of the variable (using 
the special dot val variable), the label (using dot lbl), or both. Here we use 
dot val to specify that PHONE2 should be set to missing if the original value is 
zero or eight.


Notice in all these examples that we create a new variable for the transformed 
version, so that we don't overwrite the original. This can be useful so that 
you can engage in some trial and error until you get the variable transformed as 
you want it.

---

# `lbl_na_if()`

- Works with both values (`.val`) and labels (`.lbl`)


```r
drop_labels &lt;- c("N/A", "Suppressed (2012 and 2015 ACS)")

data$PHONE3 &lt;- lbl_na_if(data$PHONE, ~.lbl %in% drop_labels) %&gt;%
  as_factor()
```

???
Because lbl_na_if works with both values and labels, we could accomplish the 
same thing by referring to the labels. This time, we specify that PHONE3 should 
be set to missing if the original label was "N/A" or "Suppressed".

---

# `lbl_collapse()`
- `lbl_collapse()` allows you to take advantage of the hierarchical
  structure of value labels.

```r
ipums_val_labels(data$EDUCD)
#&gt; # A tibble: 44 x 2
#&gt;      val lbl                      
#&gt;    &lt;int&gt; &lt;chr&gt;                    
#&gt;  1     0 N/A or no schooling      
#&gt;  2     1 N/A                      
#&gt;  3     2 No schooling completed   
#&gt;  4    10 Nursery school to grade 4
#&gt;  5    11 Nursery school, preschool
#&gt;  6    12 Kindergarten             
#&gt;  7    13 Grade 1, 2, 3, or 4      
#&gt;  8    14 Grade 1                  
#&gt;  9    15 Grade 2                  
#&gt; 10    16 Grade 3                  
#&gt; # ... with 34 more rows
```


???
[Read bullet point]

We see here that values less than 10 indicate missing or no schooling values; 
values between 10 and 19 all capture levels between nursery school and grade 4; 
and so on.

---

# `lbl_collapse()`

- Maybe this is too much detail, so we want to collapse the last digit.


```r
data$EDUCD2 &lt;- lbl_collapse(data$EDUCD, ~.val %/% 10) %&gt;%
  as_factor()
```

. . .

<div id="htmlwidget-633e35576325d0eff936" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-633e35576325d0eff936">{"x":{"filter":"none","data":[["[0] N/A or no schooling","[1] N/A","[2] No schooling completed","[10] Nursery school to grade 4","[11] Nursery school, preschool","[12] Kindergarten","[13] Grade 1, 2, 3, or 4","[14] Grade 1","[15] Grade 2","[16] Grade 3","[17] Grade 4","[20] Grade 5, 6, 7, or 8","[21] Grade 5 or 6","[22] Grade 5","[23] Grade 6","[24] Grade 7 or 8","[25] Grade 7","[26] Grade 8","[30] Grade 9","[40] Grade 10","[50] Grade 11","[60] Grade 12","[61] 12th grade, no diploma","[62] High school graduate or GED","[63] Regular high school diploma","[64] GED or alternative credential","[65] Some college, but less than 1 year","[70] 1 year of college","[71] 1 or more years of college credit, no degree","[80] 2 years of college","[81] Associate's degree, type not specified","[82] Associate's degree, occupational program","[83] Associate's degree, academic program","[90] 3 years of college","[100] 4 years of college","[101] Bachelor's degree","[110] 5+ years of college","[111] 6 years of college (6+ in 1960-1970)","[112] 7 years of college","[113] 8+ years of college","[114] Master's degree","[115] Professional degree beyond a bachelor's degree","[116] Doctoral degree","[999] Missing"],["N/A or no schooling","N/A or no schooling","N/A or no schooling","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Nursery school to grade 4","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 5, 6, 7, or 8","Grade 9","Grade 10","Grade 11","Grade 12","Grade 12","Grade 12","Grade 12","Grade 12","Grade 12","1 year of college","1 year of college","2 years of college","2 years of college","2 years of college","2 years of college","3 years of college","4 years of college","4 years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","5+ years of college","Missing"],[11811,50098,50114,40324,14976,14611,15871,10715,11500,11836,12399,27934,16637,12274,14020,28589,15962,40520,39440,46037,44797,67118,17653,170139,102651,12312,65168,13985,156110,12989,69752,9937,3888,6712,15917,147940,4280,3062,1303,1799,42621,13744,6898,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>

???
[Read bullet point]
The label collapse function allows you to collapse values based on a 
hierarchical coding scheme. Here we use the integer division operator to group 
values with the same first digit, and label collapse automatically assigns the 
label of the smallest original value. You can interpret this integer division 
expression as "how many times does 10 go into this value?" For original values 
0, 1, and 2, the answer is that 10 goes into the value zero times, so those 
values all receive the same output value, with the label coming from the 
smallest original value. I think the details of what's going on here take a bit 
of time to unpack, but hopefully this gives you a sense of the usefulness and 
power of this function.

---

# `lbl_relabel()`
- `lbl_relabel()` has more granular control of what the values are assigned to.


```r
levels(data$EDUCD2)
#&gt;  [1] "N/A or no schooling"      
#&gt;  [2] "Nursery school to grade 4"
#&gt;  [3] "Grade 5, 6, 7, or 8"      
#&gt;  [4] "Grade 9"                  
#&gt;  [5] "Grade 10"                 
#&gt;  [6] "Grade 11"                 
#&gt;  [7] "Grade 12"                 
#&gt;  [8] "1 year of college"        
#&gt;  [9] "2 years of college"       
#&gt; [10] "3 years of college"       
#&gt; [11] "4 years of college"       
#&gt; [12] "5+ years of college"      
#&gt; [13] "Missing"
```

---

# `lbl_relabel()`

- Maybe the education variable is still too specific.


```r
data$EDUCD3 &lt;- data$EDUCD %&gt;%
  lbl_collapse(~.val %/% 10) %&gt;% 
  lbl_relabel(
    lbl(2, "Less than High School") ~.val &gt; 0 &amp; .val &lt; 6,
    lbl(3, "High school") ~.lbl == "Grade 12",
    lbl(4, "Some college") ~str_detect(.lbl, "^[123] year(s)? of college$"),
    lbl(5, "College or more") ~.val %in% c(10, 11)
  ) %&gt;%
  as_factor()
```

---

# `lbl_relabel()`

<div id="htmlwidget-09ef2bba4399f1a93478" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-09ef2bba4399f1a93478">{"x":{"filter":"none","data":[["[0] N/A or no schooling","[1] N/A","[2] No schooling completed","[10] Nursery school to grade 4","[11] Nursery school, preschool","[12] Kindergarten","[13] Grade 1, 2, 3, or 4","[14] Grade 1","[15] Grade 2","[16] Grade 3","[17] Grade 4","[20] Grade 5, 6, 7, or 8","[21] Grade 5 or 6","[22] Grade 5","[23] Grade 6","[24] Grade 7 or 8","[25] Grade 7","[26] Grade 8","[30] Grade 9","[40] Grade 10","[50] Grade 11","[60] Grade 12","[61] 12th grade, no diploma","[62] High school graduate or GED","[63] Regular high school diploma","[64] GED or alternative credential","[65] Some college, but less than 1 year","[70] 1 year of college","[71] 1 or more years of college credit, no degree","[80] 2 years of college","[81] Associate's degree, type not specified","[82] Associate's degree, occupational program","[83] Associate's degree, academic program","[90] 3 years of college","[100] 4 years of college","[101] Bachelor's degree","[110] 5+ years of college","[111] 6 years of college (6+ in 1960-1970)","[112] 7 years of college","[113] 8+ years of college","[114] Master's degree","[115] Professional degree beyond a bachelor's degree","[116] Doctoral degree","[999] Missing"],["N/A or no schooling","N/A or no schooling","N/A or no schooling","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","Less than High School","High school","High school","High school","High school","High school","High school","Some college","Some college","Some college","Some college","Some college","Some college","Some college","College or more","College or more","College or more","College or more","College or more","College or more","College or more","College or more","College or more","Missing"],[11811,50098,50114,40324,14976,14611,15871,10715,11500,11836,12399,27934,16637,12274,14020,28589,15962,40520,39440,46037,44797,67118,17653,170139,102651,12312,65168,13985,156110,12989,69752,9937,3888,6712,15917,147940,4280,3062,1303,1799,42621,13744,6898,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>before ([val] label)<\/th>\n      <th>after<\/th>\n      <th>count<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"scrollY":"200px","scrollCollapse":true,"paging":false,"bInfo":false,"columnDefs":[{"className":"dt-right","targets":2}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>






---


# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

.strong[`5.` Brief analysis example]

`6.` Working with IPUMS geographic data

`7.` Preview of IPUMS API functionality

]


---

# Phone availability 
- Now that they're factors, ready for use as regular R data

```r
graph_data &lt;- data %&gt;%
  group_by(YEAR) %&gt;%
  summarize(
    `% with phone` = weighted.mean(
      PHONE2 == "Yes, phone available", PERWT, na.rm = TRUE
    ),
    .groups = "drop"
  )

ggplot(graph_data, aes(x = YEAR, y = `% with phone`)) +
  geom_point() +
  geom_line() + 
  labs(
    title = "Percent of Minnesota with phone line",
    subtitle = paste0("Data source: ", ddi$ipums_project),
    caption = paste(
      strwrap(ipums_var_desc(ddi, PHONE), 90), 
      collapse = "\n"
    )
  )
```

???
Microdata often needs to be summarized at a higher level for visualization. In 
this case, if we want to make a graph of phone availability over time, we need 
to first summarize at the year level.

The first block of code computes the weighted proportion of persons with access
to a phone in each year. Once our data are summarized so that each row
represents a value for one year, we can make a graph by year.

---

# Phone availability
![](ipumsr_webinar_files/figure-html/graph1-1.png)&lt;!-- --&gt;

---

# Interpretation

&gt; The 2008 ACS and 2008 PRCS instructed respondents to include cell 
&gt; phone service; prior to 2008, this was not made explicit.
&gt; 
&gt; - https://usa.ipums.org/usa-action/variables/PHONE#comparability_section

---

# Phone availability by education
![](ipumsr_webinar_files/figure-html/graph2-1.png)&lt;!-- --&gt;

---

# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

.strong[`6.` Working with IPUMS geographic data]

`7.` Preview of IPUMS API functionality

]



---

# Getting geographic data

- For IPUMS USA (and several other projects), we provide geographic boundaries 
  as well. For many areas, this includes harmonizing boundary changes over time.

- Our extract includes the variable CONSPUMA, for "Consistent Public Use 
  Microdata Areas"

- Note: CONSPUMA units are large
  - For finer geographic detail, check out IPUMS NHGIS

???
Geographic boundary data is usually found via a "Geography and GIS" link on the
left sidebar of the home page for a data collection, under the heading
"Supplemental Data".

---

# Loading shape data

- `ipumsr` provides support for both sf and sp data; we'll use sf here

- Load with the `ipums_read_sf()` function (mostly just a wrapper around
  `sf::read_sf()`)



```r
shape_data &lt;- read_ipums_sf("shape/")
#&gt; options:        ENCODING=latin1 
#&gt; Reading layer `ipums_conspuma' from data source 
#&gt;   `C:\Users\ehrli097\Desktop\Projects\ipumsr-webinar\shape\ipums_conspuma.shp' 
#&gt;   using driver `ESRI Shapefile'
#&gt; Simple feature collection with 543 features and 3 fields
#&gt; Geometry type: MULTIPOLYGON
#&gt; Dimension:     XY
#&gt; Bounding box:  xmin: -7115713 ymin: -1337508 xmax: 2258225 ymax: 4591616
#&gt; Projected CRS: USA_Contiguous_Albers_Equal_Area_Conic
```

???
The sp package (short for "spatial") has been around since 2005. It is more
established and some other R spatial packages might still assume you are using
sp data structures. The sf package (short for "simple features") is newer, but 
seems to be on the rise as an alternative sp for some use cases.

---

# Loading shape data


```r
as_tibble(shape_data)
#&gt; # A tibble: 543 x 4
#&gt;    CONSPUMA STATEFIP State     
#&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;     
#&gt;  1      540 02       Alaska    
#&gt;  2      541 02       Alaska    
#&gt;  3      542 15       Hawaii    
#&gt;  4      491 51       Virginia  
#&gt;  5      492 51       Virginia  
#&gt;  6      493 51       Virginia  
#&gt;  7      494 51       Virginia  
#&gt;  8      495 53       Washington
#&gt;  9      496 53       Washington
#&gt; 10      497 53       Washington
#&gt; # ... with 533 more rows, and 1 more variable:
#&gt; #   geometry &lt;MULTIPOLYGON [m]&gt;
```
???
At the risk of oversimplifying, an sf object is basically a tibble or data.frame
with a special geometry column. That simplification helps me understand the 
process of joining the sf object to data.

---

# Joining shape data
- `ipumsr` has helpers for merging data that work with both sf and sp structures 


```r
conspuma_data &lt;- data %&gt;%
  group_by(CONSPUMA, YEAR) %&gt;%
  summarize(
    `% with phone` = weighted.mean(
      PHONE2 == "Yes, phone available", PERWT, na.rm = TRUE
    ),
    .groups = "drop"
  )

conspuma_data &lt;- ipums_shape_inner_join(
  conspuma_data, 
  shape_data, 
  by = "CONSPUMA"
)
#&gt; Some observations were lost in the join (533 observations in the shape file and
#&gt; 11 obervation in data). See `join_failures(...)` for more details.
```

???
Before joining to shape data, we need to summarize our person level data at the 
level of the geography we are joining to. Thus, the first block of code computes 
the weighted proportion of persons with access to a phone for each CONSPUMA 
unit in each year. Once our data are summarized so that each row represents a 
value for one CONSPUMA unit in one year, we can join to the sf object we loaded 
above.

---

# Plotting shape data
- Since the addition of `geom_sf()`, ggplot2 can plot sf data:
![](ipumsr_webinar_files/figure-html/graph3-1.png)&lt;!-- --&gt;

???
For more information on IPUMS geographic data, see the ipumsr vignette on
working with geographic data, or one of several collection-specific recorded
webinars on that topic.

---
# Overview

.greyed-out[


`1.` What is IPUMS?

`2.` What is ipumsr, and why use it?

`3.` Reading data into R

`4.` Exploring and manipulating metadata

`5.` Brief analysis example

`6.` Working with IPUMS geographic data

.strong[`7.` Preview of IPUMS API functionality]

]


---

# API Timeline

- Currently in internal testing

- Beta testing before the end of 2021

- IPUMS USA public launch early 2022

???
The API is not yet publicly available, but we wanted to offer a preview of the 
functionality that will soon be available in ipumsr.

We plan to support creating extracts via API for all of our data collections, 
but that support will be rolled out one collection at a time, to allow us to 
thoroughly test that the extract API is working as expected for each collection.

IPUMS USA is the first collection that will be supported, and we are currently
doing internal testing of the API for USA. We'll put out a call for beta testers
before the end of this year, but feel free to reach out in the meantime if you
want to be added to that list. We expect to open up the USA extract API to all
IPUMS USA users in the first few months of next year, depending on what sort of
issues arise during beta testing.

Another important note is that there is already a public API for the IPUMS NHGIS
collection, which offers access to tabular data from the US Census Bureau, as
well as corresponding geographic boundaries. ipumsr does not yet include
functions for interacting with the NHGIS API, but there is a guide to
interacting with that API in R, which we'll share a link to at the end of these
slides, and we plan to add that functionality to ipumsr sometime next year.

---

# What can I do with the API?

- Define and submit extract requests

--

- Check extract status or "wait" for an extract to finish

--

- Download completed extracts

--

- Get info on past extracts

--

- Share extract definitions

???
So, your next question might be, "what will I be able to do with this API?" 
Here's the high-level overview:

You'll be able to:

Define and submit extract requests.

Check the status of a submitted extract, or have R "wait" for an extract to 
finish by periodically checking the status until it is ready to download.

Download completed data extracts.

Get information on past extracts, including the ability to pull down the 
definition of a previous extract, revise that definition, and resubmit it.

And finally, you can save your extract definition to a JSON file, allowing you 
to share the extract definition with other users for collaboration or 
reproducibility. Saving as JSON makes the definition more easily shareable 
across languages, since R is not the only way to interact with the IPUMS API -- 
you can also call the API using a general purpose tool like curl, and IPUMS is 
developing API client tools for Python in parallel with the R client tools that 
will be part of the ipumsr package.

---

# What can't I do with the API?

- Bypass the extract system entirely

--

- Explore what data are available

--

- Use all features of the extract system (at least not right away)


???
The other important question to answer is what the API can't do.

Most importantly, it can't deliver data "on demand" -- extracts are still 
created through the same extract system used by the website, which means you 
have to wait for your extract to process before you can download it.

In other words, the API does not create a separate system of accessing IPUMS
data, but rather provides a programmatic way to create and download extracts
through the existing extract system.

Secondly, you can't use the API to explore what data are available from IPUMS. 
We plan to add a public metadata API, but the timeline on that is more unknown.

A third limitation is that API users will not initially have access to all the
bells and whistles of the extract system, such as the ability to attach 
characteristics of family members such as spouses or children. We plan to add 
these capabilities once the core functionality is well-tested and stable.

---

# Pipe-friendly example


```r
my_extract &lt;- define_extract(
  "usa", 
  "Occupation by sex and age",
  c("us2017a", "us2018a"), 
  c("SEX", "AGE", "IND", "OCC")
)
```

--

Extract definition to data in one piped expression!


```r
data &lt;- my_extract %&gt;% 
  submit_extract() %&gt;% 
  wait_for_extract() %&gt;% 
  download_extract() %&gt;% 
  read_ipums_micro()
```

???
Now let's get to some example code! We'll start with a brief example that shows 
a typical API workflow using the "pipe" operator from the magrittr package, 
which is often used in conjunction with tidyverse packages such as dplyr.

We start by defining an extract object using the `define_extract()` function, 
and specifying 

- a data collection -- in this case, "usa" 
- an extract description -- "Occupation by sex and age"
- samples -- here we're asking for the 2017 and 2018 American Community Survey 
- and variables -- sex, age, industry and occupation.

The next code chunk shows how we can go from this extract definition to having 
our extract data available in our R session in one piped expression. For any of 
you who are unfamiliar with the pipe operator, it can be read aloud as the word 
"then". So this piped expression says, take "my_extract", *then* submit extract, 
*then* wait for extract, *then* download extract, *then* read in the data using 
`read_ipums_micro()`.

Since we have to wait for the extract to process, this piped expression will 
take a bit of time to execute, depending on the size of your extract, but if we 
have time we will actually run some code like this during the Q&amp;A so you can 
see it in action.

---

# Pipe-friendly example


```r
my_extract &lt;- define_extract(
  "usa", 
  "Occupation by sex and age",
  c("us2017a", "us2018a"), 
  c("SEX", "AGE", "IND", "OCC")
)
```

Extract definition to data in one piped expression!


```r
data &lt;- my_extract |&gt; 
  submit_extract() |&gt; 
  wait_for_extract() |&gt; 
  download_extract() |&gt; 
  read_ipums_micro()
```


???
And just for fun, here's what the same piped expression looks like with the new
base R pipe, available as of R 4.1.

---

# Revise and resubmit

Get definition of my most recent extract:


```r
old_extract &lt;- get_recent_extracts_info_list("usa", 1)[[1]]
```

--

Or if we know the number of the extract:


```r
old_extract &lt;- get_extract_info("usa:33")
```


???
Another handy workflow where using the extract API is a "revise and resubmit" 
workflow. Often, you might realize that you should have added one more or a few 
more variables to your previous extract, and you just want to resubmit that 
extract with a few additional variables.

To do this with ipumsr functions, you first pull down the definition of your 
most recent extract using the function `get_recent_extracts_info_list()`, which 
can return information on up to 10 recent extracts. Here, we specify that we 
only want one recent extract (the most recent one), but because this function 
always returns a list, we also have to subset the first element.

Alternatively, if we know the extract number of the extract we want to revise, 
we can use `get_extract_info()` and specify a shorthand notation for USA 
extract number 33, for example.

---

# Revise and resubmit

Then add a variable and resubmit:


```r
old_extract %&gt;% 
  revise_extract(vars_to_add = "EDUC") %&gt;% 
  submit_extract()
```

???
Once we have the old extract definition, we can pass it to the 
`revise_extract()` function to add a variable, then resubmit it.

The `revise_extract()` function currently allows you to add and remove variables
and samples, as well as change the description, data format, or data structure
of your extract definition.

---

# Share your extract definition


```r
save_extract_as_json(my_extract, "my_extract.json")
```

--

Another user can read that definition back in with:


```r
cloned_extract &lt;- define_extract_from_json("my_extract.json", "usa")
```

???
One thing that really excites us about the API is the ability to share extract
definitions to facilitate collaboration or reproducibility.

To write your extract out to a JSON file, you can use the 
`save_extract_as_json()` function as shown here.

Saving as JSON makes it easier to share an extract definition with another user 
who might not use R -- they can use the JSON definition to submit the extract 
using curl or Python, possibly using the currently in-development IPUMS API 
client tools in the "ipumspy" module.

If you are using ipumsr, the `define_extract_from_json()` function will create
an extract object from a JSON-formatted definition shared by someone else.

---

# Resources
- Email us: ipums+cran@umn.edu

- ipumsr github: https://github.com/mnpopcenter/ipumsr

- This presentation: https://github.com/dtburk/ipumsr-webinar

- ipumsr website, with vignettes: http://tech.popdata.org/ipumsr/index.html

- IPUMS tutorials page: https://www.ipums.org/support/tutorials

- *Geocomputation with R* book: https://geocompr.robinlovelace.net/
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
